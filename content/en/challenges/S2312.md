+++
title = 'Streaming ASR Porting and Optimization for SG2002'
date = 2023-12-28T15:09:10+08:00
toc = true
slug = 'S2312'
cid = 'S2312'
award = '15000 CNY'
summary = "Natural voice interaction is an important form of human-machine interfacing. However, as high-precision ASR models are computationally intensive, these computation projects are usually run on the cloud, worsening the experience. This program aims to port high-precision streaming ASR to Sophgo's SG2002 processor. You may choose between Chinese and English models. The goal is to achieve minimum word error rate whilst running on limited RAM (256MBytes) and a rate of RTF<1. You may reference Kaldi, Wenet, and other open source speech recognition projects for your port."
+++

## Program Description

Natural voice interaction is an important form of human-machine interfacing. However, as high-precision ASR models are computationally intensive, these computation projects are usually run on the cloud, worsening the experience.

This program aims to port high-precision streaming ASR to Sophgo's SG2002 processor. You may choose between Chinese and English models. The goal is to achieve minimum word error rate whilst running on limited RAM (256MBytes) and a rate of RTF<1.

You may reference Kaldi, Wenet, and other open source speech recognition projects for your port.

## Rubrics

1. Offline speech recognition using SG2002's on-board microphone.
2. You are allowed to use RVV0.7, TPU, and other computational resources available on the SG2002.
3. The judging will take into account memory usage, real time factor (RTF), word error rate (WER).
4. The model must run within SG2002's 256MBytes of RAM.
5. Real time factor: Lower is better, the model must support streamed recognition at RTF<1.
6. Word error rate: The model must achieve a WER must be lower than 10% to be considered usable; 5% is ideal.
7. The host will assess both accuracy and performance and assign scores to each submission based on a predetermined weighted scale. The highest scoring submission wins.

**Assessment Platform: LicheeRV Nano/Milk-V duo 256** [^1]

## 提交说明

* 提交仓库链接为 <TBA>
* 请以 Pull Request 的形式，将结果提交到上述仓库中。
* 提交时，请详细说明复现所需要的软件环境，可以参照「验收说明」内默认软件环境做修改。
* 在比赛期间，所有经过优化过的内容的提交方式可以有：
  1. 二进制的形式
  2. 加密源码的形式（加密信息需通过邮件发送至 rvspoc@cyberlimes.cn）
  3. 源码形式
* 最终结果公布后，需对提交内容进行完整开源。
* 组委会会在比赛结束后（即 2024 年 2 月 16 日以后），关闭赛题仓库的 Pull Request 通道，并开始对结果进行验收。

## 验收说明

1. 验证平台为 **SG2022**（LicheeRV Nano/Milk-V duo 256 [^1]），固定的硬件规格。
2. 组委会会在条件 1 的基础上，使用如下软件环境，将经过多次跑分所产生的平均值作为基线，与选手优化过后的数据进行比较：
   - 待定
3. 满足「产出及评分要求」所列出 7 条项目。
4. **根据赛题的实际优化进展，针对未考虑到的方面，随着比赛进程的推进可能会有调整，请保持对赛事网站的关注，最终解释权归属于比赛的赛题评审委员会。**

## Notice on Intellectual Properties and Open Source Licenses

All program submissions must be open source and committed to a specified repository. The participant(s) (author) holds rights to their work. The host encourages contributing any changes made to the upstream.


[^1]: LicheeRV Nano/Milk-V duo 256 purchase link:
      - LicheeRV Nano： https://sipeed.com/licheerv-nano
      - Milk-V duo 256： https://milkv.io/duo (please select the 256M model)
