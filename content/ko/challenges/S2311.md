+++
title = 'Duo에서 Baby LLaMA 2의 속도 최적화 (어린이용 이야기 시나리오)'
date = 2023-11-27T19:57:09+08:00
toc = true
slug = 'S2311'
cid = 'S2311'
award = '20000 CNY'
summary = 'Milk-V Duo와 같은 작은 보드에서 Baby LLaMA 2를 실행하는 것은 큰 도전입니다. 이 대회의 목적은 Milk-V Duo 플랫폼에서 Baby LLaMA 2의 성능을 향상시키는 것이며, 목표는 초당 토큰 처리 속도를 높이는 것입니다. 참가자들은 경량 기술과 컴파일러 최적화 전략을 활용하여, 마이크로폰의 음성 입력이나 커맨드 라인 입력 프롬프트 등 다양한 방법을 결합하여 이야기를 들려주는 로봇의 데모를 개발해야 합니다. 이 데모는 스피커를 통해 출력되며, 샤오미 미토 이야기 로봇의 프로토타입 디자인을 참조할 수 있습니다.'
+++

## 프로젝트 설명：

Milk-V Duo와 같은 작은 보드에서 Baby LLaMA 2를 실행하는 것은 큰 도전입니다. 이 대회의 목적은 Milk-V Duo 플랫폼에서 Baby LLaMA 2의 성능을 향상시키는 것이며, 목표는 초당 토큰 처리 속도를 높이는 것입니다. 참가자들은 경량 기술과 컴파일러 최적화 전략을 활용하여, 마이크로폰의 음성 입력이나 커맨드 라인 입력 프롬프트 등 다양한 방법을 결합하여 이야기를 들려주는 로봇의 데모를 개발해야 합니다. 이 데모는 스피커를 통해 출력되며, 샤오미 미토 이야기 로봇의 프로토타입 디자인을 참조할 수 있습니다.

## 결과물 및 평가 요건：

1. 평가 기준은 정확도와 성능의 두 가지 측면에 초점을 맞춥니다. 동일한 입력에 대해 기준 테스트를 사용하여 참가 작품의 정확도와 성능을 평가합니다.
2. 정확도 점수는 참가 작품의 출력과 기준 출력의 차이 테스트 결과를 사용하여 측정하며, 최적화 기술이 모델 추론의 정확도에 미치는 영향을 반영합니다. 성능 점수는 초당 계산되는 토큰의 수를 사용하여 측정하며, 참가 작품의 성능 최적화 효과를 직접 반영합니다.
3. 텍스트에서 음성으로의 변환(TTS) 시간은 별도로 계산됩니다.
4. 최종적으로, 위원회는 참가 작품의 정확도와 성능의 전체적인 성능을 기반으로 평가하고, 두 가지는 대회의 평가 위원회가 설정한 가중치 비율에 따라 최종 점수를 계산하여, 최고 점수를 획득한 참가자가 승자가 됩니다.

## 제출 설명

* 제출 리포지토리 링크는 https://github.com/plctlab/rvspoc-s2311-llama2 입니다.
* 결과는 위 리포지토리에 Pull Request 형태로 제출해주세요.
* 제출 시, 재현에 필요한 소프트웨어 환경을 자세히 설명해주세요. '검수 설명'에 기록된 기본 소프트웨어 환경을 참고하여 필요에 따라 변경을 추가하세요.
* 대회 기간 동안 최적화된 내용을 제출하는 방법은 다음과 같습니다:
   1. 바이너리 형식
   2. 암호화된 소스 코드 형식(암호화 정보는 rvspoc@cyberlimes.cn으로 이메일로 보내야 합니다)
   3. 소스 코드 형식
* 최종 결과 공개 후, 제출 내용을 완전히 오픈소스화해야 합니다.
* 주최측은, 대회 종료 후(즉, 2024년 ~~2월 16일~~ 2월 29일 이후), 대회 과제의 리포지토리 Pull Request 채널을 닫고 결과 검수를 시작합니다.

## 검수 설명

1.  검증 플랫폼은 **Milk-V Duo**, **64MB** 버전입니다.
   - 검수 시 동일한 사양의 TF 카드를 통일하여 사용합니다.
   - SWAP 사용은 권장되지 않습니다.
   - CPU 오버클럭은 하지 않습니다.
   - 추가적인 냉각 장치는 사용하지 않습니다.
2. Duo 상의 시스템에 특별한 요구사항은 없습니다.
3. Baby Llama 2 리포지토리는 https://github.com/karpathy/llama2.c 입니다.
4. 주최자는 조건 1의 기반 위에 다음과 같은 소프트웨어 환경을 사용하여 여러 번의 스코어링을 진행한 결과의 평균값을 기준선으로 설정하고, 참가자의 최적화 후 데이터와 비교할 것입니다:
   1. Baby Llama 2의 바이너리는 상기 리포지토리의 원본 수정되지 않은 C 파일을 -Ofast로 컴파일한 것을 사용합니다.
   2. 컴파일러는 Milk-V 공식이 제공하는 크로스 컴파일 툴체인을 사용합니다 (버전은 추후 결정됩니다).
   3. 시스템은 기본 Milk-V Duo 시스템 이미지를 사용합니다 (버전은 추후 결정됩니다).
   4. 통일된 입력 및 파라미터를 사용합니다 (구체적인 내용은 추후 결정됩니다).
   5. 다음의 대규모 언어 모델 파일을 사용합니다:
      * 순수 FP32 추론용 (즉, run.c 파일 사용 시), Baby Llama 2 리포지토리에서 제공하는 15M 파라미터 모델 (순수 FP32 모델)을 사용합니다.
      * 해당 sha256sum은 cd590644d963867a2b6e5a1107f51fad663c41d79c149fbecbbb1f95fa81f49a 입니다.
5. 정확성 평가 설명: 고정된 입력 파라미터 (결정된 난수 사용)에 대해, 출력 내용은 고정된 값이어야 합니다. 따라서, 주최자는 조건 4 하에서 생성된 run.c 바이너리의 출력 내용과 비교할 것입니다. 차이가 발생한 경우, 사람이 일반적으로 사용하는 문법으로 판단되며, 문법이 올바른 경우 점수 감점 없이, 문법에 오류가 있는 경우 점수를 감점합니다. 감점 비율은 추후 결정됩니다.
6. 성능 평가 설명: 각 제출 결과는 30회 실행되며, 명백히 다른 최고 점수와 최저 점수를 제외한 후, 평균값이 기록됩니다.
7. 텍스트에서 음성으로 변환(TTS) 기능을 완성한 경우, 그 구현 정도에 따라 추가 점수가 부여됩니다. 추가 점수 비율은 추후 결정됩니다.
8. 최종 결과에는 각 항목에 대한 자세한 설명이 포함됩니다.
9. **대회의 실제 최적화 진행 상황에 따라 고려되지 않은 측면은 대회의 진행에 따라 조정될 수 있으며, 대회 웹사이트를 계속 주시하시기 바랍니다. 최종 해석권은 대회 과제 심사위원회에 있습니다.**

## 지적 재산권 및 오픈 소스 라이선스에 관한 설명：

모든 참가 작품은 오픈 소스로 공개되어야 하며, 주최자가 지정하는 저장소에 제출해야 합니다. 참가자(저자)는 작품의 모든 권리를 보유합니다. 주최자는 참가자가 결과물을 업스트림에 피드백하여 기여하는 것을 권장합니다.

## Resources

* Live Replay & Documents (중국어)： [plctlab/rvspoc:archives/2023/Docs/S2311](https://github.com/plctlab/rvspoc/tree/main/archives/2023/Docs/S2311)
